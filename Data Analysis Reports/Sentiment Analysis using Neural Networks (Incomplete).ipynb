{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15069122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import string\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import twint \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4727124",
   "metadata": {},
   "source": [
    "## Understanding and Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9a5c287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neutral  \\\n",
       "0   neutral   \n",
       "1  negative   \n",
       "2  positive   \n",
       "3  positive   \n",
       "4  positive   \n",
       "\n",
       "  According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .  \n",
       "0  Technopolis plans to develop in stages an area...                                                                               \n",
       "1  The international electronic industry company ...                                                                               \n",
       "2  With the new production plant the company woul...                                                                               \n",
       "3  According to the company 's updated strategy f...                                                                               \n",
       "4  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...                                                                               "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding the data\n",
    "df = pd.read_csv('all-data.csv', encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ecf6a",
   "metadata": {},
   "source": [
    "Data comprised of headlines. and three labels - neutral, positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8141faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "df = df.rename(columns={'neutral':'sentiment','According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .':'headlines'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bacef4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising data\n",
    "data = df['sentiment'].value_counts()\n",
    "plt.bar(data.index, data.values)\n",
    "plt.ylabel('Occurrences', fontsize=12)\n",
    "plt.xlabel('Sentiment', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c055568",
   "metadata": {},
   "source": [
    "## Cleaning and Tokenizing data\n",
    "\n",
    "- Remove any punctuation and turn all data into a lowercase format to make it suitable for lematization and analysis.\n",
    "- Break down headlines into its individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bb5236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categories to numeric\n",
    "sentiment  = {'positive': 0,'neutral': 1,'negative': -1} \n",
    "\n",
    "df.sentiment = [sentiment[label] for label in df.sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21f40df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning headlines \n",
    "def clean_data(df):\n",
    "    clean_headlines = df.apply(lambda headlines: headlines.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "    return clean_headlines\n",
    "    \n",
    "# Tokenize data\n",
    "def tokenize_data(df):\n",
    "    tokenized_headlines = df.apply(lambda headline: headline.split())\n",
    "    return tokenized_headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4be793",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "- Lemmatization is a way to normalize text data. It links words with similar meanings to one word.\n",
    "- The lemma of a set of words is its dictionary form. For example, [break, breaks, broke, broken] are all indexed by the lemma 'break'. \n",
    "- By using lematization, all the words in headlines are reduced to their lemma which makes it much more useful for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eedabcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_data(df):\n",
    "    # Analyses the tokenized headline and returns the list in its lematized form\n",
    "    def lemmatize_headline(headline):\n",
    "        lemmas = [lemmatizer.lemmatize(word) for word in headline]\n",
    "        return headline\n",
    "    return df.apply(lemmatize_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97085935",
   "metadata": {},
   "source": [
    "### Stop Words\n",
    "- Stop words are the most common words in the language.\n",
    "- Since these words are normally irrelevant, they should be removed. \n",
    "- However, it should be noted that certain words such as But, And, etc may be relevant to sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a691ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_data(df):\n",
    "    stop_words = stopwords.words('english')\n",
    "    # Removes stop words from each headline\n",
    "    def remove_stopwords_headline(headline):\n",
    "        headline = [word for word in headline if word not in stop_words]\n",
    "        return ' '.join(headline)\n",
    "    return df.apply(remove_stopwords_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1929bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, filter neutral news:\n",
    "df = df[df['sentiment'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5e449",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43cc2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing - Done this way for demonstration purposes\n",
    "\n",
    "# clean data from training data\n",
    "df['clean_data'] = clean_data(df['headlines'])\n",
    "# tokenize data from training data\n",
    "df['tokenize_data']  = tokenize_data(df['clean_data'])\n",
    "# lemmatize data from training data\n",
    "df['lemmatize_data']  = lemmatize_data(df['tokenize_data'])\n",
    "# remove stop words from training data\n",
    "df['processed_data']  = remove_stopwords_data(df['lemmatize_data'])\n",
    "# Lastly, filter neutral news:\n",
    "df = df[df['sentiment'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22bb90",
   "metadata": {},
   "source": [
    "## Split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8506b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only require the processed data \n",
    "df = df[['sentiment','processed_data']]\n",
    "\n",
    "# Splitting into training and test data\n",
    "data, label = df['processed_data'], df['sentiment']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42,stratify=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b6519",
   "metadata": {},
   "source": [
    "## TensorFlow Tokenizer\n",
    "- TensorFlow's Tokenizer package allows us to turn each text into a sequence of integers suitable for data analysis. The integer returned is based on the number of instances of that word in that dataset. \n",
    "- We use this to allow our data to be used in machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "240d5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "max_features = 1000\n",
    "\n",
    "# Tokenization \n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token = \"<OOV>\") \n",
    "# creates a vocabulary index based on word frequency using training dataset\n",
    "tokenizer.fit_on_texts(data)\n",
    "# All unique words are given an index:\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ab5c83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2785, 47)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforms each word using its respective value in the vocabulary index \n",
    "# to produce a sequence of numbers.\n",
    "training_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "# padding transforms the sequence into a 2D Numpy array to allow us to\n",
    "# use the data to train the models\n",
    "training_padded = pad_sequences(training_sequences, padding = 'post')\n",
    "test_padded = pad_sequences(test_sequences, padding = 'post')\n",
    "\n",
    "# unique tokens\n",
    "vocab_size = len(training_padded) \n",
    "training_padded.shape # 3482 sequences, each with 38 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f15a6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting a threshold for the number of words in each text\n",
    "num_tokens=[len(tokens) for tokens in training_sequences+test_sequences]\n",
    "num_tokens=np.array(num_tokens)\n",
    "max_tokens=np.mean(num_tokens)+2*np.std(num_tokens)\n",
    "max_tokens=int(max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d15504",
   "metadata": {},
   "source": [
    "# Applying Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df8e1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import machine learning models\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b7a4a",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "### Turns vocabulary index into vectors of fixed size.\n",
    "<code>     \n",
    "tf.keras.layers.Embedding(vocab_size, embedding_dim, input_legnth = max_length)\n",
    "</code>\n",
    "\n",
    "Parameter breakdown:\n",
    "1) Vocab size is the largest integer in the word index that the model will take.\n",
    "\n",
    "2) Size of the vector space in which the words will be embedded.\n",
    "\n",
    "3) Length of the input sequences (set to 1000 to take largest headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "427d93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488fd3d",
   "metadata": {},
   "source": [
    "notes:\n",
    "    how many layers in the middle? usually 1\n",
    "    how many nodes in hidden layer? midway between input and output\n",
    "    activation function -> introduces non-linearity \n",
    "    learning rate -> how much does the step affect our weight/bias\n",
    "    momentum -> how much past outcomes affect weight/bias\n",
    "    iterations and desired error level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5d6d958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2785, 47)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input dimensions\n",
    "training_padded.shape # 2437 sequences, each with 47 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f48df1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 1000\n",
    "embedding_size=50 \n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b86caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.Sequential()\n",
    "\n",
    "# Embedding layer will take text as input, convert it to a vector as output\n",
    "model.add(tf.keras.layers.Embedding(input_dim = max_features,\n",
    "                   output_dim = embedding_size,\n",
    "                    input_length = max_tokens,\n",
    "                    name = 'embedding_layer'\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39d84cab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"gru_6\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3308/136780637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#               return_sequences=True) # if true this layer odel creates multiple outputs. If the following layer has one neuron, which means the following layer creates the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#with the sigmoid activation function, we receive an output between 0 and 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    212\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\u001b[0m\u001b[0;32m    215\u001b[0m                          \u001b[1;34m'is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m                          \u001b[1;34mf'expected ndim={spec.ndim}, found ndim={ndim}. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"gru_6\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 4)"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.GRU(units=16, # number of neurons \n",
    "              return_sequences=True) # if true this layer odel creates multiple outputs. If the following layer has one neuron, which means the following layer creates the output. \n",
    ")\n",
    "model.add(tf.keras.layers.GRU(units=8, return_sequences=True))\n",
    "model.add(tf.keras.layers.GRU(units=4))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))#with the sigmoid activation function, we receive an output between 0 and 1.\n",
    "optimizer=Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab572d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a797c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d30cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184de5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceea255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88447ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7c30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfa4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe285917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # learns the direction of each word epoch by epoch\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_size, input_length = max_tokens),\n",
    "    # pool using global average\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(47, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation ='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73cc0da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 25), found shape=(None, 47)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3308/1189313260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\nurul\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 25), found shape=(None, 47)\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(training_padded, y_train, epochs = 30, validation_data = (test_padded, y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47e2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5af368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224f060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1c011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6c8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c8f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057a135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bab819b",
   "metadata": {},
   "source": [
    "## Building Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 2000, solver = 'lbfgs')\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c753dd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0744bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f4de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7cbaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c6509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b26df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac1e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b5ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464bfa44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d08f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84bec42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06523e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/sentiment-analysis-using-logistic-regression-and-naive-bayes-16b806eb4c4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee099e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    '''\n",
    "    # calculate the sigmoid of z\n",
    "    h = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    \n",
    "    m = len(x)\n",
    "  \n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x,theta)\n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = (-1/m)*(np.dot(y.T,np.log(h)) + np.dot((1-y).T,np.log(1-h)))\n",
    "        \n",
    "        # update the weights theta\n",
    "        theta = theta - (alpha/m)*np.dot(x.T, h-y)\n",
    "        \n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "        \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word,1),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word,0),0)\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39514125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a7731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ffe668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab7190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713a718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623bdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59e2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2f740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb744fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq(df):\n",
    "    hash_map = {}\n",
    "    for headline in df:\n",
    "        for word in headline:\n",
    "            if word in hash_map:\n",
    "                hash_map[word] += 1\n",
    "            else:\n",
    "                hash_map[word] = 0\n",
    "    return hash_map\n",
    "\n",
    "word_freq(x_train['final'])\n",
    "word_freq(x_test['final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf9addc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd151e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets news headlines from popular sites\n",
    "\n",
    "def news_fetch(query):\n",
    "    return\n",
    "\n",
    "# Gets popular tweets from twitter\n",
    "\n",
    "def twitter_fetch(query):\n",
    "    c = twint.Config()\n",
    "    \n",
    "    c.Search = query\n",
    "    c.Lang = 'en'\n",
    "    c.Hide_output = True\n",
    "    c.Pandas = True\n",
    "    c.Min_likes = 100\n",
    "    c.Limit = 5000\n",
    "    twint.run.Search(c)\n",
    "    data = twint.storage.panda.Tweets_df\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "for source in positive:\n",
    "    for tweet in source:\n",
    "        clean_data.append(tweet.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "        \n",
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429bb7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # removes punctuation and turns tweets to lower case\n",
    "    clean_data = df.apply(lambda tweet: tweet.lower().translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_negative = clean_data(negative)\n",
    "clean_positive = clean_data(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317db93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ae9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "pd.DataFrame(hashmap_negative.values(), index = hashmap_negative).sort_values(by = 0, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment():\n",
    "    return\n",
    "\n",
    "def average_sentiment_score():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = twitter_fetch(\"(inflation OR market underperform)\")\n",
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190c8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6791073",
   "metadata": {},
   "outputs": [],
   "source": [
    "'towardsdatascience.com/5-ways-to-develop-a-sentiment-analyser-in-machine-learning-e8352872118'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\n",
    "# list of negative sentiment words: from github/mkulakowski2\n",
    "with open('positive-words.txt') as file:\n",
    "    positive = [x.strip('\\n') for x in file]\n",
    "    \n",
    "# list of positive sentiment words:\n",
    "with open('negative-words.txt') as file:\n",
    "    negative = [x.strip('\\n') for x in file]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
